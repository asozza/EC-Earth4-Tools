- base.context:
    experiment:
      id: TEST
      description: A new ECE4 coupled experiment

      schedule:
        all: !rrule >
          DTSTART:19900101
          RRULE:FREQ=YEARLY;UNTIL=19920101

      # if true, remove the experiment folder
      run_from_scratch: false

      nemo:
        start_from:
          # Chose ONE of the options below:
          # 1) Cold start
          #    Do not fill in any of the parameters below
          # 2) Start from initialisation of temperature and salinity (ts)
          #    Set 'ts_state.file' with the path to a NetCDF file that contains the 3D
          #    temperature (thetao) and salinity (so) fields. Optionally, set
          #    'ts_state.weight_file' if the ts_state.file needs to be interpolated.
          #    For the provided WOA Levitus climatology use 'ts_state.file: woa13-levitus.nc'
          #    and 'ts_state.weight_file: weights_WOA13d1_2_eorca1_bilinear.nc'
          # 3) Start from global restart files
          #    Set 'restart.dir' where the 'restart.nc' (oce) and 'restart_ice.nc' (ice) files
          #    are located
          ts_state:
            file:
            weight_file:
          restart:
            dir:

      monitoring:
        activate: false

    model_config:
      components: [oifs, rnfm, nemo, xios, oasis]

      oifs:
        grid: !noparse "{{model_config.oifs.all_grids.TL63L31}}"

      nemo:
        grid: !noparse "{{model_config.nemo.all_grids.ORCA2L31}}"

    job:
      # Configure launch method, one of:
      #   slurm-hetjob  # SLURM heterogeneous job
      #   slurm-mp-taskset  # SLURM srun with multi-prog, hostfile and taskset
      #   slurm-wrapper-taskset  # SLURM srun with wrapper, hostfile and taskset
      #   slurm-shell  # SLURM + generic shell script template (needs job.launch.shell.script)
      # For configuration of the respective method, see next section!
      launch:
        method: slurm-wrapper-taskset
        #method: slurm-shell
        #shell:
        #  script: run-srun-multiprog.sh

      # If true, the job will resubmit itself to run a further leg
      resubmit: false

      slurm:
        sbatch:
          opts:
            account: "spitdav2"
            time: "06:00:00"
            output: !noparse "{{experiment.id}}.log"
            job-name: !noparse "ECE4_{{experiment.id}}"
            qos: "np"
            ntasks-per-core: 1
        srun:
          args: [--label, --kill-on-bad-exit]

- when: job.launch.method in ["slurm-hetjob", "slurm-mp-taskset", "slurm-shell"]
  base.context:
    job:
      oifs:
        ntasks: 175
        ntasks_per_node: 128
        omp_num_threads: 1
        omp_stacksize: "128M"
      nemo:
        ntasks: 77
        ntasks_per_node: 128
      xios:
        ntasks: 1
        ntasks_per_node: 1

- when: job.launch.method in ["slurm-wrapper-taskset"]
  base.context:
    job:
      oifs:
        omp_num_threads: 1
        omp_stacksize: "64M"
        use_hyperthreads: false
      groups:
        - { nodes: 1, xios: 1, oifs: 126, rnfm: 1 }
        - { nodes: 1, oifs: 49, nemo: 77 }